"""
Ù…Ø§Ú˜ÙˆÙ„ Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø®Ø¨Ø§Ø± Ø§Ø±Ø²Ù‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒØªØ§Ù„

Ø§ÛŒÙ† Ù…Ø§Ú˜ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ù…Ù‡Ù… Ø§Ø±Ø²Ù‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒØªØ§Ù„ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø¹ØªØ¨Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
Ùˆ Ù‚Ø§Ø¨Ù„ÛŒØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒØŒ ØªØ±Ø¬Ù…Ù‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø§Ø®Ø¨Ø§Ø± Ø±Ø§ Ù†ÛŒØ² ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
"""

import os
import logging
import requests
import json
import time
from datetime import datetime, timedelta
import pytz
from bs4 import BeautifulSoup
import trafilatura
from openai import OpenAI
from typing import List, Dict, Any, Optional

# ØªÙ†Ø¸ÛŒÙ… Ù„Ø§Ú¯Ø±
logger = logging.getLogger(__name__)

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª API
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
CRYPTOCOMPARE_API_KEY = os.environ.get("CRYPTOCOMPARE_API_KEY")

# ØªÙ†Ø¸ÛŒÙ… Ù…Ù†Ø·Ù‚Ù‡ Ø²Ù…Ø§Ù†ÛŒ ØªÙˆØ±Ù†ØªÙˆ
toronto_tz = pytz.timezone('America/Toronto')


def get_cryptocompare_news(limit: int = 10, lang: str = "EN") -> List[Dict[str, Any]]:
    """
    Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø§Ø² CryptoCompare API
    
    Args:
        limit (int): ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
        lang (str): Ø²Ø¨Ø§Ù† Ø§Ø®Ø¨Ø§Ø±
        
    Returns:
        List[Dict[str, Any]]: Ù„ÛŒØ³Øª Ø§Ø®Ø¨Ø§Ø± Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯Ù‡
    """
    try:
        url = f"https://min-api.cryptocompare.com/data/v2/news/?lang={lang}&api_key={CRYPTOCOMPARE_API_KEY}&limit={limit}"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            if data.get("Response") == "Success" or data.get("Type") == 100:
                return data.get("Data", [])
            else:
                logger.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ø³Ø® CryptoCompare: {data.get('Message')}")
                return []
        else:
            logger.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª CryptoCompare: {response.status_code}")
            return []
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø§Ø² CryptoCompare: {str(e)}")
        return []


def get_coindesk_news(limit: int = 5) -> List[Dict[str, Any]]:
    """
    Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø§Ø² ÙˆØ¨â€ŒØ³Ø§ÛŒØª CoinDesk
    
    Args:
        limit (int): ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
        
    Returns:
        List[Dict[str, Any]]: Ù„ÛŒØ³Øª Ø§Ø®Ø¨Ø§Ø± Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯Ù‡
    """
    try:
        url = "https://www.coindesk.com/"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        response = requests.get(url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            articles = []
            
            for article in soup.select('article')[:limit]:
                try:
                    title_elem = article.select_one('h6') or article.select_one('h5') or article.select_one('h4')
                    link_elem = article.select_one('a')
                    
                    if title_elem and link_elem:
                        title = title_elem.text.strip()
                        link = link_elem.get('href', '')
                        if not link.startswith('http'):
                            link = f"https://www.coindesk.com{link}"
                        
                        # Ø¯Ø±ÛŒØ§ÙØª ØªØµÙˆÛŒØ± Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯
                        img_elem = article.select_one('img')
                        image_url = img_elem.get('src', '') if img_elem else ''
                        
                        articles.append({
                            "title": title,
                            "url": link,
                            "imageurl": image_url,
                            "source": "CoinDesk",
                            "published_on": int(time.time())
                        })
                except Exception as e:
                    logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ù‚Ø§Ù„Ù‡ CoinDesk: {str(e)}")
                    continue
            
            return articles
        else:
            logger.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª CoinDesk: {response.status_code}")
            return []
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø§Ø² CoinDesk: {str(e)}")
        return []


def get_cointelegraph_news(limit: int = 5) -> List[Dict[str, Any]]:
    """
    Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø§Ø² ÙˆØ¨â€ŒØ³Ø§ÛŒØª CoinTelegraph
    
    Args:
        limit (int): ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
        
    Returns:
        List[Dict[str, Any]]: Ù„ÛŒØ³Øª Ø§Ø®Ø¨Ø§Ø± Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯Ù‡
    """
    try:
        url = "https://cointelegraph.com/"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        response = requests.get(url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            articles = []
            
            # Ù…Ù‚Ø§Ù„Ø§Øª Ø§ØµÙ„ÛŒ
            for article in soup.select('.post-card')[:limit]:
                try:
                    title_elem = article.select_one('.post-card__title')
                    link_elem = article.select_one('a.post-card__link')
                    
                    if title_elem and link_elem:
                        title = title_elem.text.strip()
                        link = link_elem.get('href', '')
                        if not link.startswith('http'):
                            link = f"https://cointelegraph.com{link}"
                        
                        # Ø¯Ø±ÛŒØ§ÙØª ØªØµÙˆÛŒØ± Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯
                        img_elem = article.select_one('img')
                        image_url = img_elem.get('src', '') if img_elem else ''
                        
                        articles.append({
                            "title": title,
                            "url": link,
                            "imageurl": image_url,
                            "source": "CoinTelegraph",
                            "published_on": int(time.time())
                        })
                except Exception as e:
                    logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ù‚Ø§Ù„Ù‡ CoinTelegraph: {str(e)}")
                    continue
            
            return articles
        else:
            logger.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª CoinTelegraph: {response.status_code}")
            return []
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø§Ø² CoinTelegraph: {str(e)}")
        return []


def extract_article_content(url: str) -> str:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆØ§ÛŒ Ù…Ù‚Ø§Ù„Ù‡ Ø§Ø² URL
    
    Args:
        url (str): Ø¢Ø¯Ø±Ø³ Ù…Ù‚Ø§Ù„Ù‡
        
    Returns:
        str: Ù…Ø­ØªÙˆØ§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ù…Ù‚Ø§Ù„Ù‡
    """
    try:
        downloaded = trafilatura.fetch_url(url)
        if downloaded:
            text = trafilatura.extract(downloaded)
            if text:
                return text
        
        # Ø§Ú¯Ø± trafilatura Ù†ØªÙˆØ§Ù†Ø¯ Ù…Ø­ØªÙˆØ§ Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†Ø¯ØŒ Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        response = requests.get(url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            # Ø­Ø°Ù Ø§Ù„Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒ
            for elem in soup(['script', 'style', 'nav', 'footer', 'header']):
                elem.decompose()
            
            # Ú¯Ø±ÙØªÙ† Ù…Ø­ØªÙˆØ§ÛŒ Ø§ØµÙ„ÛŒ
            article_content = soup.select_one('article') or soup.select_one('.article-content') or soup.select_one('.content')
            if article_content:
                return article_content.get_text(separator='\n').strip()
            
            # Ø§Ú¯Ø± Ù…Ø­ØªÙˆØ§ÛŒ Ø§ØµÙ„ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ø§Ø² Ù…ØªÙ† Ú©Ù„ ØµÙØ­Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            return soup.get_text(separator='\n').strip()
        
        return ""
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆØ§ÛŒ Ù…Ù‚Ø§Ù„Ù‡: {str(e)}")
        return ""


def translate_news(news_items: List[Dict[str, Any]], target_language: str = "fa") -> List[Dict[str, Any]]:
    """
    ØªØ±Ø¬Ù…Ù‡ Ø¹Ù†Ø§ÙˆÛŒÙ† Ø§Ø®Ø¨Ø§Ø± Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² OpenAI API
    
    Args:
        news_items (List[Dict[str, Any]]): Ù„ÛŒØ³Øª Ø§Ø®Ø¨Ø§Ø±
        target_language (str): Ø²Ø¨Ø§Ù† Ù…Ù‚ØµØ¯ (fa Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)
        
    Returns:
        List[Dict[str, Any]]: Ù„ÛŒØ³Øª Ø§Ø®Ø¨Ø§Ø± Ø¨Ø§ Ø¹Ù†Ø§ÙˆÛŒÙ† ØªØ±Ø¬Ù…Ù‡ Ø´Ø¯Ù‡
    """
    if not OPENAI_API_KEY or not news_items:
        return news_items
    
    try:
        client = OpenAI(api_key=OPENAI_API_KEY)
        translated_items = []
        
        # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø± Û´ Ø®Ø¨Ø± Ø¯Ø± ÛŒÚ© Ø¯Ø±Ø®ÙˆØ§Ø³Øª
        for i in range(0, len(news_items), 4):
            batch = news_items[i:i+4]
            titles = [item['title'] for item in batch]
            
            # Ø³Ø§Ø®Øª Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø³ØªÛŒ Ùˆ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² + Ø¨Ø±Ø§ÛŒ Ú†Ø³Ø¨Ø§Ù†Ø¯Ù† Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¬Ø§ÛŒ f-string
            titles_formatted = "\n".join([f"{idx+1}. {title}" for idx, title in enumerate(titles)])
            prompt = "ØªØ±Ø¬Ù…Ù‡ Ø¹Ù†Ø§ÙˆÛŒÙ† Ø²ÛŒØ± Ø§Ø² Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø·Ø¨ÛŒØ¹ÛŒ Ùˆ Ø±ÙˆØ§Ù†:\n\n" + titles_formatted + "\n\nÙ¾Ø§Ø³Ø® Ø±Ø§ ÙÙ‚Ø· Ø¨Ù‡ ØµÙˆØ±Øª Ø¹Ù†Ø§ÙˆÛŒÙ† ØªØ±Ø¬Ù…Ù‡ Ø´Ø¯Ù‡ Ø¨Ø§ Ø´Ù…Ø§Ø±Ù‡ Ø¨Ø¯Ù‡ÛŒØ¯ØŒ Ø¨Ø¯ÙˆÙ† Ù‡ÛŒÚ† ØªÙˆØ¶ÛŒØ­ ÛŒØ§ Ù…Ù‚Ø¯Ù…Ù‡."
            
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
            )
            
            translation_text = response.choices[0].message.content.strip()
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ±Ø¬Ù…Ù‡â€ŒÙ‡Ø§
            translations = []
            for line in translation_text.split('\n'):
                line = line.strip()
                if line and any(line.startswith(f"{i}.") for i in range(1, 10)):
                    # Ø­Ø°Ù Ø´Ù…Ø§Ø±Ù‡ Ø§Ø² Ø§Ø¨ØªØ¯Ø§ÛŒ Ø®Ø·
                    translations.append(line.split('.', 1)[1].strip())
            
            # Ø§Ø¹Ù…Ø§Ù„ ØªØ±Ø¬Ù…Ù‡ Ø¨Ù‡ Ø§Ø®Ø¨Ø§Ø±
            for j, item in enumerate(batch):
                if j < len(translations):
                    translated_title = translations[j]
                    item['title_fa'] = translated_title
                else:
                    item['title_fa'] = item['title']  # Ø§Ú¯Ø± ØªØ±Ø¬Ù…Ù‡ Ù…ÙˆÙÙ‚ Ù†Ø¨ÙˆØ¯ØŒ Ø§Ø² Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
                
                translated_items.append(item)
        
        return translated_items
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ø¬Ù…Ù‡ Ø§Ø®Ø¨Ø§Ø±: {str(e)}")
        # Ø§Ú¯Ø± ØªØ±Ø¬Ù…Ù‡ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´ÙˆØ¯ØŒ Ø§Ø®Ø¨Ø§Ø± Ø§ØµÙ„ÛŒ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ…
        for item in news_items:
            item['title_fa'] = item['title']
        return news_items


def get_crypto_news(limit: int = 10, translate: bool = True) -> List[Dict[str, Any]]:
    """
    Ø¯Ø±ÛŒØ§ÙØª Ùˆ ØªØ±Ú©ÛŒØ¨ Ø§Ø®Ø¨Ø§Ø± Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø®ØªÙ„Ù
    
    Args:
        limit (int): ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø§Ø®Ø¨Ø§Ø± Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
        translate (bool): Ø¢ÛŒØ§ Ø§Ø®Ø¨Ø§Ø± ØªØ±Ø¬Ù…Ù‡ Ø´ÙˆÙ†Ø¯
        
    Returns:
        List[Dict[str, Any]]: Ù„ÛŒØ³Øª Ø§Ø®Ø¨Ø§Ø± ØªØ±Ú©ÛŒØ¨ Ø´Ø¯Ù‡
    """
    # ØªØ¹ÛŒÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø± Ø§Ø² Ù‡Ø± Ù…Ù†Ø¨Ø¹
    per_source = limit // 3 + 1
    
    # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø®ØªÙ„Ù
    cryptocompare_news = get_cryptocompare_news(limit=per_source)
    coindesk_news = get_coindesk_news(limit=per_source)
    cointelegraph_news = get_cointelegraph_news(limit=per_source)
    
    # ØªØ±Ú©ÛŒØ¨ Ø§Ø®Ø¨Ø§Ø±
    all_news = []
    all_news.extend(cryptocompare_news)
    all_news.extend(coindesk_news)
    all_news.extend(cointelegraph_news)
    
    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ´Ø§Ø± (Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ø§Ø®Ø¨Ø§Ø± Ø§Ø¨ØªØ¯Ø§)
    all_news.sort(key=lambda x: x.get('published_on', 0), reverse=True)
    
    # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ØªØ¹Ø¯Ø§Ø¯ Ø§Ø®Ø¨Ø§Ø±
    all_news = all_news[:limit]
    
    # ØªØ±Ø¬Ù…Ù‡ Ø¹Ù†Ø§ÙˆÛŒÙ† Ø§Ø®Ø¨Ø§Ø± Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
    if translate and OPENAI_API_KEY:
        all_news = translate_news(all_news)
    else:
        # Ø§Ú¯Ø± ØªØ±Ø¬Ù…Ù‡ Ù†ÛŒØ§Ø² Ù†ÛŒØ³Øª ÛŒØ§ Ø§Ù…Ú©Ø§Ù† Ø¢Ù† ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯
        for item in all_news:
            item['title_fa'] = item['title']
    
    # ØªØ¨Ø¯ÛŒÙ„ timestamp Ø¨Ù‡ ØªØ§Ø±ÛŒØ® Ùˆ Ø²Ù…Ø§Ù† Ø®ÙˆØ§Ù†Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù†Ø·Ù‚Ù‡ Ø²Ù…Ø§Ù†ÛŒ ØªÙˆØ±Ù†ØªÙˆ
    for item in all_news:
        if 'published_on' in item:
            dt_utc = datetime.utcfromtimestamp(item['published_on'])
            dt_toronto = dt_utc.replace(tzinfo=pytz.utc).astimezone(toronto_tz)
            item['published_date'] = dt_toronto.strftime('%Y-%m-%d %H:%M')
    
    return all_news


def get_crypto_sentiment_analysis() -> Dict[str, Any]:
    """
    Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§Ø²Ø§Ø± Ø§Ø±Ø²Ù‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒØªØ§Ù„
    
    Returns:
        Dict[str, Any]: ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§Ø²Ø§Ø±
    """
    # Ø§Ú¯Ø± Open AI API Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¨Ø§Ø´Ø¯ØŒ Ø¯Ø§Ø¯Ù‡ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ…
    if not OPENAI_API_KEY:
        return {
            "overall_sentiment": "neutral",
            "sentiment_score": 50,
            "bitcoin_sentiment": "neutral",
            "ethereum_sentiment": "neutral",
            "updated_at": datetime.now(toronto_tz).strftime('%Y-%m-%d %H:%M'),
            "data_available": False
        }
    
    try:
        # Ø¯Ø±ÛŒØ§ÙØª Ú†Ù†Ø¯ Ø®Ø¨Ø± Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
        news = get_crypto_news(limit=5, translate=False)
        
        # Ø§Ú¯Ø± Ø®Ø¨Ø±ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯
        if not news:
            return {
                "overall_sentiment": "neutral",
                "sentiment_score": 50,
                "bitcoin_sentiment": "neutral",
                "ethereum_sentiment": "neutral",
                "updated_at": datetime.now(toronto_tz).strftime('%Y-%m-%d %H:%M'),
                "data_available": False
            }
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
        news_titles = "\n".join([f"- {item['title']}" for item in news])
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # Ø³Ø§Ø®Øª Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø³ØªÛŒ Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² f-string Ø¨Ø§ Ø­Ø±ÙˆÙ ÙØ§Ø±Ø³ÛŒ
        prompt_first_part = "Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø¹Ù†Ø§ÙˆÛŒÙ† Ø§Ø®Ø¨Ø§Ø± Ø²ÛŒØ±ØŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§Ø²Ø§Ø± Ø±Ù…Ø²Ø§Ø±Ø²Ù‡Ø§ Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯:\n\n"
        prompt_second_part = """

Ù„Ø·ÙØ§Ù‹ Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª ÛŒÚ© JSON Ø¨Ø§ Ø§ÛŒÙ† Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯:
{
  "overall_sentiment": "bullish/neutral/bearish",
  "sentiment_score": <Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† 0 ØªØ§ 100. 0 Ú©Ø§Ù…Ù„Ø§Ù‹ bearishØŒ 50 neutralØŒ 100 Ú©Ø§Ù…Ù„Ø§Ù‹ bullish>,
  "bitcoin_sentiment": "bullish/neutral/bearish",
  "ethereum_sentiment": "bullish/neutral/bearish",
  "short_analysis": "<ÛŒÚ© ÛŒØ§ Ø¯Ùˆ Ø¬Ù…Ù„Ù‡ ØªØ­Ù„ÛŒÙ„ Ú©Ù„ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ>"
}
"""
        prompt = prompt_first_part + news_titles + prompt_second_part
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0.2,
        )
        
        result = json.loads(response.choices[0].message.content)
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø²Ù…Ø§Ù† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ
        result["updated_at"] = datetime.now(toronto_tz).strftime('%Y-%m-%d %H:%M')
        result["data_available"] = True
        
        return result
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§Ø²Ø§Ø±: {str(e)}")
        return {
            "overall_sentiment": "neutral",
            "sentiment_score": 50,
            "bitcoin_sentiment": "neutral",
            "ethereum_sentiment": "neutral",
            "updated_at": datetime.now(toronto_tz).strftime('%Y-%m-%d %H:%M'),
            "data_available": False,
            "error": str(e)
        }


def get_fear_greed_index() -> Dict[str, Any]:
    """
    Ø¯Ø±ÛŒØ§ÙØª Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹ Ø¨Ø§Ø²Ø§Ø±
    
    Returns:
        Dict[str, Any]: Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹
    """
    try:
        url = "https://api.alternative.me/fng/"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            if data.get("metadata", {}).get("error") is None:
                fng_data = data.get("data", [{}])[0]
                
                # ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø¨Ù‡ Ù…Ù†Ø·Ù‚Ù‡ Ø²Ù…Ø§Ù†ÛŒ ØªÙˆØ±Ù†ØªÙˆ
                time_until_update = fng_data.get("time_until_update", "")
                timestamp = int(fng_data.get("timestamp", "0"))
                dt_utc = datetime.utcfromtimestamp(timestamp)
                dt_toronto = dt_utc.replace(tzinfo=pytz.utc).astimezone(toronto_tz)
                
                return {
                    "value": int(fng_data.get("value", 50)),
                    "value_classification": fng_data.get("value_classification", "Neutral"),
                    "timestamp": timestamp,
                    "date": dt_toronto.strftime('%Y-%m-%d %H:%M'),
                    "time_until_update": time_until_update,
                    "data_available": True
                }
        
        # Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¨Ø§Ø´Ø¯ ÛŒØ§ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´ÙˆÛŒÙ…
        return {
            "value": 50,
            "value_classification": "Neutral",
            "timestamp": int(time.time()),
            "date": datetime.now(toronto_tz).strftime('%Y-%m-%d %H:%M'),
            "data_available": False
        }
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹: {str(e)}")
        return {
            "value": 50,
            "value_classification": "Neutral",
            "timestamp": int(time.time()),
            "date": datetime.now(toronto_tz).strftime('%Y-%m-%d %H:%M'),
            "data_available": False,
            "error": str(e)
        }


def get_market_insights() -> Dict[str, Any]:
    """
    Ø¯Ø±ÛŒØ§ÙØª Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ Ùˆ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø§Ø±Ø²Ù‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒØªØ§Ù„
    
    Returns:
        Dict[str, Any]: Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ Ùˆ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±
    """
    # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    news = get_crypto_news(limit=8, translate=True)
    sentiment = get_crypto_sentiment_analysis()
    fear_greed = get_fear_greed_index()
    
    # ØªØ±Ú©ÛŒØ¨ Ùˆ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    return {
        "news": news,
        "sentiment": sentiment,
        "fear_greed_index": fear_greed,
        "updated_at": datetime.now(toronto_tz).strftime('%Y-%m-%d %H:%M')
    }


def format_market_insights_for_telegram(insights: Dict[str, Any]) -> str:
    """
    Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…
    
    Args:
        insights (Dict[str, Any]): Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±
        
    Returns:
        str: Ù…ØªÙ† Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù…
    """
    news = insights.get('news', [])
    sentiment = insights.get('sentiment', {})
    fear_greed = insights.get('fear_greed_index', {})
    
    # ØªÙ†Ø¸ÛŒÙ… Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§Ø²Ø§Ø±
    sentiment_emoji = "ğŸ˜"  # neutral by default
    if sentiment.get('overall_sentiment') == 'bullish':
        sentiment_emoji = "ğŸš€"
    elif sentiment.get('overall_sentiment') == 'bearish':
        sentiment_emoji = "ğŸ»"
    
    # ØªÙ†Ø¸ÛŒÙ… Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹
    fng_value = fear_greed.get('value', 50)
    fng_emoji = "ğŸ˜"  # neutral by default
    if fng_value >= 75:
        fng_emoji = "ğŸ˜ˆ"  # extreme greed
    elif fng_value >= 55:
        fng_emoji = "ğŸ˜€"  # greed
    elif fng_value <= 25:
        fng_emoji = "ğŸ˜±"  # extreme fear
    elif fng_value <= 45:
        fng_emoji = "ğŸ˜¨"  # fear
    
    # Ø³Ø§Ø®Øª Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø§Ø¬ØªÙ†Ø§Ø¨ Ø§Ø² Ù…Ø´Ú©Ù„Ø§Øª f-string Ø¨Ø§ Ø­Ø±ÙˆÙ ÙØ§Ø±Ø³ÛŒ
    message_parts = [
        "ğŸŒ *Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§Ø²Ø§Ø± Ø§Ø±Ø²Ù‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒØªØ§Ù„* ğŸŒ",
        f"ØªØ§Ø±ÛŒØ®: {insights.get('updated_at')}",
        "",
        f"{sentiment_emoji} *ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§Ø²Ø§Ø±:*",
        f"â€¢ ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ: {sentiment.get('overall_sentiment', 'Ù†Ø§Ù…Ø´Ø®Øµ')}",
        f"â€¢ Ø§Ù…ØªÛŒØ§Ø²: {sentiment.get('sentiment_score', 50)}",
        f"â€¢ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ†: {sentiment.get('bitcoin_sentiment', 'Ù†Ø§Ù…Ø´Ø®Øµ')}",
        f"â€¢ Ø§ØªØ±ÛŒÙˆÙ…: {sentiment.get('ethereum_sentiment', 'Ù†Ø§Ù…Ø´Ø®Øµ')}",
        "",
        f"{fng_emoji} *Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹:*",
        f"â€¢ Ø¹Ø¯Ø¯: {fear_greed.get('value', 'Ù†Ø§Ù…Ø´Ø®Øµ')}",
        f"â€¢ ÙˆØ¶Ø¹ÛŒØª: {fear_greed.get('value_classification', 'Ù†Ø§Ù…Ø´Ø®Øµ')}",
        "",
        "ğŸ“° *Ø¢Ø®Ø±ÛŒÙ† Ø§Ø®Ø¨Ø§Ø±:*"
    ]
    message = "\n".join(message_parts)
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø®Ø¨Ø§Ø±
    for i, item in enumerate(news[:5], 1):
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø³Ø®Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¹Ù†ÙˆØ§Ù† Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯
        title = item.get('title_fa', item.get('title', ''))
        url = item.get('url', '')
        source = item.get('source', '')
        published_date = item.get('published_date', '')
        
        message += f"\n{i}. [{title}]({url})"
        message += f"\n   Ù…Ù†Ø¨Ø¹: {source} | {published_date}"
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ­Ù„ÛŒÙ„
    if sentiment.get('short_analysis'):
        message += f"\n\nğŸ” *ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡:*\n{sentiment.get('short_analysis')}"
    
    return message


def get_crypto_news_formatted_for_telegram() -> str:
    """
    Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø§Ø±Ø²Ù‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒØªØ§Ù„ Ø¨Ø§ Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù…
    
    Returns:
        str: Ù…ØªÙ† Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù…
    """
    insights = get_market_insights()
    return format_market_insights_for_telegram(insights)


if __name__ == "__main__":
    # ØªØ³Øª Ù…Ø§Ú˜ÙˆÙ„
    print("Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø§Ø±Ø²Ù‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒØªØ§Ù„...")
    news = get_crypto_news(limit=5, translate=True)
    for item in news:
        print(f"Ø¹Ù†ÙˆØ§Ù†: {item.get('title')}")
        print(f"ØªØ±Ø¬Ù…Ù‡: {item.get('title_fa', '')}")
        print(f"Ù…Ù†Ø¨Ø¹: {item.get('source')}")
        print(f"ØªØ§Ø±ÛŒØ®: {item.get('published_date', '')}")
        print(f"Ù„ÛŒÙ†Ú©: {item.get('url')}")
        print("-" * 50)
    
    print("\nØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§Ø²Ø§Ø±:")
    sentiment = get_crypto_sentiment_analysis()
    print(json.dumps(sentiment, indent=2, ensure_ascii=False))
    
    print("\nØ´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹:")
    fear_greed = get_fear_greed_index()
    print(json.dumps(fear_greed, indent=2, ensure_ascii=False))
    
    print("\nÚ¯Ø²Ø§Ø±Ø´ ØªÙ„Ú¯Ø±Ø§Ù…:")
    telegram_message = get_crypto_news_formatted_for_telegram()
    print(telegram_message)